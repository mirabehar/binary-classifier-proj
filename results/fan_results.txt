flucchetti@timblee:~/366proj$ python3 classifier.py
data/balanced_fan.csv
(1, 1)

classify_bow_counts
X_cols[50:60]:  ['108', '109', '10k', '10months', '10pages', '10pm', '10th', '10wordreview', '10x', '10yr']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.71      0.70      0.70     22217
           1       0.70      0.72      0.71     22349

    accuracy                           0.71     44566
   macro avg       0.71      0.71      0.71     44566
weighted avg       0.71      0.71      0.71     44566

0.70746757617915
Precision-Recall AUC: 0.78
ROC AUC: 0.71
"H kills V at the end."
  - Predicted as: '1'

"I never expected it to end with a big wedding..."
  - Predicted as: '1'

"a b c d e f g"
  - Predicted as: '0'

"ajvhsdbnmu Woooooow fs qon vjk vkuhg dkj!!!!"
  - Predicted as: '0'

"ajvhsdbnmu fs qon vjk vkuhg dkj!!!!"
  - Predicted as: '0'

"What a cliffhanger!"
  - Predicted as: '0'

"How sad that A K dies."
  - Predicted as: '1'

"I don't believe it!!"
  - Predicted as: '1'

"Another one for the hell of it."
  - Predicted as: '0'

"Really I am trying to trick you, why did it have to happen"
  - Predicted as: '1'

"NOOOOOOOOO"
  - Predicted as: '1'

"NO"
  - Predicted as: '1'

"YES"
  - Predicted as: '1'

"This isn't a spoiler."
  - Predicted as: '0'

"I can't believe DV was L's father!"
  - Predicted as: '1'


classify_many_feats
FEATURE_LIST:  ['s_loc']
X_cols[120:130]:  ['142', '143', '144', '145', '146', '147', '1471', '148', '1485', '14ish']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.69      0.68      0.68     22269
           1       0.68      0.69      0.69     22297

    accuracy                           0.69     44566
   macro avg       0.69      0.69      0.69     44566
weighted avg       0.69      0.69      0.69     44566

0.6857021047435264
Precision-Recall AUC: 0.76
ROC AUC: 0.69

classify_many_feats
FEATURE_LIST:  ['userID']
X_cols[120:130]:  ['142', '143', '144', '145', '146', '147', '1471', '148', '1485', '14ish']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.71      0.70      0.70     22281
           1       0.70      0.71      0.71     22285

    accuracy                           0.71     44566
   macro avg       0.71      0.71      0.71     44566
weighted avg       0.71      0.71      0.71     44566

0.7054480994480097
Precision-Recall AUC: 0.78
ROC AUC: 0.71

classify_many_feats
FEATURE_LIST:  ['rating']
X_cols[120:130]:  ['142', '143', '144', '145', '146', '147', '1471', '148', '1485', '14ish']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.70      0.72      0.71     22341
           1       0.71      0.69      0.70     22225

    accuracy                           0.71     44566
   macro avg       0.71      0.71      0.71     44566
weighted avg       0.71      0.71      0.71     44566

0.7065027150742719
Precision-Recall AUC: 0.78
ROC AUC: 0.71

classify_many_feats
FEATURE_LIST:  ['userID', 's_loc']
X_cols[120:130]:  ['142', '143', '144', '145', '146', '147', '1471', '148', '1485', '14ish']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.69      0.68      0.69     22361
           1       0.69      0.70      0.69     22205

    accuracy                           0.69     44566
   macro avg       0.69      0.69      0.69     44566
weighted avg       0.69      0.69      0.69     44566

0.6897410582058071
Precision-Recall AUC: 0.77
ROC AUC: 0.69
(1, 2)

classify_bow_counts
X_cols[50:60]:  ['000 word', '000 words', '000 year', '000 years', '0000000001', '0000000001 of', '000x', '000x better', '007', '007 adam']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.72      0.71      0.71     22254
           1       0.71      0.73      0.72     22312

    accuracy                           0.72     44566
   macro avg       0.72      0.72      0.72     44566
weighted avg       0.72      0.72      0.72     44566

0.7181259255935017
Precision-Recall AUC: 0.79
ROC AUC: 0.72
"H kills V at the end."
  - Predicted as: '1'

"I never expected it to end with a big wedding..."
  - Predicted as: '1'

"a b c d e f g"
  - Predicted as: '0'

"ajvhsdbnmu Woooooow fs qon vjk vkuhg dkj!!!!"
  - Predicted as: '0'

"ajvhsdbnmu fs qon vjk vkuhg dkj!!!!"
  - Predicted as: '0'

"What a cliffhanger!"
  - Predicted as: '0'

"How sad that A K dies."
  - Predicted as: '1'

"I don't believe it!!"
  - Predicted as: '1'

"Another one for the hell of it."
  - Predicted as: '0'

"Really I am trying to trick you, why did it have to happen"
  - Predicted as: '1'

"NOOOOOOOOO"
  - Predicted as: '1'

"NO"
  - Predicted as: '1'

"YES"
  - Predicted as: '1'

"This isn't a spoiler."
  - Predicted as: '0'

"I can't believe DV was L's father!"
  - Predicted as: '1'


classify_many_feats
FEATURE_LIST:  ['s_loc']
X_cols[120:130]:  ['07 11', '07 12', '07 15', '07 31', '07 50', '07 he', '07 the', '08', '08 04', '08 15']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.75      0.65      0.70     22269
           1       0.69      0.78      0.73     22297

    accuracy                           0.72     44566
   macro avg       0.72      0.72      0.72     44566
weighted avg       0.72      0.72      0.72     44566

0.7172956962706997
Precision-Recall AUC: 0.79
ROC AUC: 0.72

classify_many_feats
FEATURE_LIST:  ['userID']
X_cols[120:130]:  ['07 11', '07 12', '07 15', '07 31', '07 50', '07 he', '07 the', '08', '08 04', '08 15']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.72      0.70      0.71     22054
           1       0.71      0.73      0.72     22512

    accuracy                           0.71     44566
   macro avg       0.71      0.71      0.71     44566
weighted avg       0.71      0.71      0.71     44566

0.7143786743257191
Precision-Recall AUC: 0.79
ROC AUC: 0.71

classify_many_feats
FEATURE_LIST:  ['rating']
X_cols[120:130]:  ['07 11', '07 12', '07 15', '07 31', '07 50', '07 he', '07 the', '08', '08 04', '08 15']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.71      0.72      0.71     22186
           1       0.72      0.70      0.71     22380

    accuracy                           0.71     44566
   macro avg       0.71      0.71      0.71     44566
weighted avg       0.71      0.71      0.71     44566

0.712965040613921
Precision-Recall AUC: 0.79
ROC AUC: 0.71

classify_many_feats
FEATURE_LIST:  ['userID', 's_loc']
X_cols[120:130]:  ['07 11', '07 12', '07 15', '07 31', '07 50', '07 he', '07 the', '08', '08 04', '08 15']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.75      0.65      0.70     22367
           1       0.69      0.78      0.73     22199

    accuracy                           0.72     44566
   macro avg       0.72      0.72      0.72     44566
weighted avg       0.72      0.72      0.72     44566

0.7164879055782435
Precision-Recall AUC: 0.79
ROC AUC: 0.72
(1, 3)

classify_bow_counts
X_cols[50:60]:  ['000 dystopian novel', '000 likes', '000 literally', '000 literally surprise', '000 more', '000 more pages', '000 of', '000 of them', '000 orcs', '000 other']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.72      0.70      0.71     22242
           1       0.71      0.73      0.72     22324

    accuracy                           0.72     44566
   macro avg       0.72      0.72      0.72     44566
weighted avg       0.72      0.72      0.72     44566

0.7167796077727415
Precision-Recall AUC: 0.79
ROC AUC: 0.72
"H kills V at the end."
  - Predicted as: '1'

"I never expected it to end with a big wedding..."
  - Predicted as: '1'

"a b c d e f g"
  - Predicted as: '0'

"ajvhsdbnmu Woooooow fs qon vjk vkuhg dkj!!!!"
  - Predicted as: '0'

"ajvhsdbnmu fs qon vjk vkuhg dkj!!!!"
  - Predicted as: '0'

"What a cliffhanger!"
  - Predicted as: '0'

"How sad that A K dies."
  - Predicted as: '1'

"I don't believe it!!"
  - Predicted as: '1'

"Another one for the hell of it."
  - Predicted as: '0'

"Really I am trying to trick you, why did it have to happen"
  - Predicted as: '1'

"NOOOOOOOOO"
  - Predicted as: '1'

"NO"
  - Predicted as: '1'

"YES"
  - Predicted as: '1'

"This isn't a spoiler."
  - Predicted as: '0'

"I can't believe DV was L's father!"
  - Predicted as: '1'


classify_many_feats
FEATURE_LIST:  ['s_loc']
X_cols[120:130]:  ['000 years old', '000 years on', '000 years or', '000 years surely', '000 years they', '0000000001', '0000000001 of', '0000000001 of the', '000x', '000x better']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.78      0.61      0.69     22379
           1       0.68      0.83      0.75     22187

    accuracy                           0.72     44566
   macro avg       0.73      0.72      0.72     44566
weighted avg       0.73      0.72      0.72     44566

0.719225418480456
Precision-Recall AUC: 0.80
ROC AUC: 0.72

classify_many_feats
FEATURE_LIST:  ['userID']
X_cols[120:130]:  ['000 years old', '000 years on', '000 years or', '000 years surely', '000 years they', '0000000001', '0000000001 of', '0000000001 of the', '000x', '000x better']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.72      0.70      0.71     22221
           1       0.71      0.73      0.72     22345

    accuracy                           0.72     44566
   macro avg       0.72      0.72      0.72     44566
weighted avg       0.72      0.72      0.72     44566

0.7171610644886236
Precision-Recall AUC: 0.79
ROC AUC: 0.72

classify_many_feats
FEATURE_LIST:  ['rating']
X_cols[120:130]:  ['000 years old', '000 years on', '000 years or', '000 years surely', '000 years they', '0000000001', '0000000001 of', '0000000001 of the', '000x', '000x better']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.71      0.72      0.72     22214
           1       0.72      0.70      0.71     22352

    accuracy                           0.71     44566
   macro avg       0.71      0.71      0.71     44566
weighted avg       0.71      0.71      0.71     44566

0.7136157608939551
Precision-Recall AUC: 0.79
ROC AUC: 0.71

classify_many_feats
FEATURE_LIST:  ['userID', 's_loc']
X_cols[120:130]:  ['000 years old', '000 years on', '000 years or', '000 years surely', '000 years they', '0000000001', '0000000001 of', '0000000001 of the', '000x', '000x better']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.78      0.61      0.69     22286
           1       0.68      0.83      0.75     22280

    accuracy                           0.72     44566
   macro avg       0.73      0.72      0.72     44566
weighted avg       0.73      0.72      0.72     44566

0.7212897724722883
Precision-Recall AUC: 0.80
ROC AUC: 0.72

classify_many_feats
FEATURE_LIST:  ['pos_bigrams']
Pos bigrams:  0               #EMPTY# beautiful-NN
1           #EMPTY# NNP-is unique-NN
2                     #EMPTY# NNP-is
3                            #EMPTY#
4    #EMPTY# NN-is NN-is NN-improved
5           #EMPTY# NN-came NNP-read
6             #EMPTY# NN-is NN-reads
7                 #EMPTY# falling-NN
8                            #EMPTY#
9                            #EMPTY#
Name: sent, dtype: object
X_cols[120:130]:  ['abandons', 'abbreviated', 'abd', 'abdicated', 'abducted', 'abducting', 'abducts', 'aber', 'abiding', 'abilities']
Total size y,X: 445656 445656
MultinomialNB()  results
              precision    recall  f1-score   support

           0       0.54      0.78      0.64     22080
           1       0.62      0.35      0.45     22486

    accuracy                           0.56     44566
   macro avg       0.58      0.57      0.54     44566
weighted avg       0.58      0.56      0.54     44566

0.5630974285329623
Precision-Recall AUC: 0.65
ROC AUC: 0.57
flucchetti@timblee:~/366proj$ c